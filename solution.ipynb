{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lpBSpzVq0Fk",
        "outputId": "3f98fa80-b22b-4fb0-9fba-b945049fc15d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.9.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 33.0 MB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.8/dist-packages (from mediapipe) (22.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mediapipe) (1.21.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from mediapipe) (1.3.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.8/dist-packages (from mediapipe) (3.19.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from mediapipe) (3.2.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.8/dist-packages (from mediapipe) (4.6.0.66)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->mediapipe) (1.15.0)\n",
            "Installing collected packages: flatbuffers, mediapipe\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires flatbuffers<2,>=1.12, but you have flatbuffers 22.12.6 which is incompatible.\u001b[0m\n",
            "Successfully installed flatbuffers-22.12.6 mediapipe-0.9.0.1\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image, ImageStat\n",
        "from google.colab.patches import cv2_imshow as cvs\n",
        "import math\n",
        "import cv2 \n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "!pip install mediapipe\n",
        "import mediapipe as mp\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0Xoa9t-hb5P"
      },
      "source": [
        "# bri con shar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAsjw5vUhRMN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2m6mDecm5FX"
      },
      "outputs": [],
      "source": [
        "def bcsfull(i):\n",
        "  from PIL import Image,ImageEnhance\n",
        "  \n",
        "  print(i)\n",
        "  img=Image.open(\"/content/drive/MyDrive/intershipdeepv/dataset/test/ourimg.png\")\n",
        "\n",
        "  \n",
        "  for i in np.arange(0,3.5,0.1):\n",
        "   factor=float(i)\n",
        "   img_brightness_obj=ImageEnhance.Brightness (img)\n",
        "   enhanced_img=img_brightness_obj.enhance(factor)\n",
        "   enhanced_img.show()\n",
        "   enhanced_img.save(\"/content/drive/MyDrive/intershipdeepv/dataset/test/img/ourdate/b/{}.png\".format(i))\n",
        "   img_brightness_obj=ImageEnhance.Contrast(img)\n",
        "   enhanced_img=img_brightness_obj.enhance(factor)\n",
        "   enhanced_img.show()\n",
        "   enhanced_img.save(\"/content/drive/MyDrive/intershipdeepv/dataset/test/img/ourdate/c/{}.png\".format(i))\n",
        "   img_brightness_obj=ImageEnhance.Sharpness(img)\n",
        "   enhanced_img=img_brightness_obj.enhance(factor)\n",
        "   enhanced_img.show()\n",
        "   i=int(i*10)\n",
        "   enhanced_img.save(\"/content/drive/MyDrive/intershipdeepv/dataset/test/img/ourdate/s/{}.png\".format(i))\n",
        "  print(\"##########\")\n",
        "  print(\"brightness\")\n",
        "  print(\"##########\")\n",
        "  dirc=\"/content/drive/MyDrive/intershipdeepv/dataset/test/img/ourdate/b/\"\n",
        "  mediapipe(dirc)\n",
        "  print(\"##########\")\n",
        "  print(\"contrast\")\n",
        "  print(\"##########\")\n",
        "  dirc=\"/content/drive/MyDrive/intershipdeepv/dataset/test/img/ourdate/c/\"\n",
        "  mediapipe(dirc)\n",
        "  print(\"##########\")\n",
        "  print(\"sharpness\")\n",
        "  print(\"##########\")\n",
        "  dirc=\"/content/drive/MyDrive/intershipdeepv/dataset/test/img/ourdate/s/\"\n",
        "  mediapipe(dirc)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZb2BgX503mY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "07509571-4834-4830-fbfb-312d9711124f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-f8d388c60ecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbcsfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-c70b0126af16>\u001b[0m in \u001b[0;36mbcsfull\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     20\u001b[0m    \u001b[0menhanced_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m    \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m    \u001b[0menhanced_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/intershipdeepv/dataset/test/img/ourdate/s/{}.png\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"##########\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"brightness\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2129\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2131\u001b[0;31m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "i=1\n",
        "import mediapipe\n",
        "\n",
        "bcsfull(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "uKz1SBN_3ng9",
        "outputId": "34d8e413-7498-4722-93db-f5da664f5bde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading model to /usr/local/lib/python3.7/dist-packages/mediapipe/modules/pose_landmark/pose_landmark_heavy.tflite\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-0d4a9ca4b5cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel_complexity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0menable_segmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     min_detection_confidence=0.5) as pose:\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/intershipdeepv/dataset/test/01-600x371.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mediapipe/python/solutions/pose.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, static_image_mode, model_complexity, smooth_landmarks, enable_segmentation, smooth_segmentation, min_detection_confidence, min_tracking_confidence)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmediapipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpose\u001b[0m\u001b[0;31m#min_tracking_confidence.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \"\"\"\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0m_download_oss_pose_landmark_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_complexity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     super().__init__(\n\u001b[1;32m    147\u001b[0m         \u001b[0mbinary_graph_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_BINARYPB_FILE_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mediapipe/python/solutions/pose.py\u001b[0m in \u001b[0;36m_download_oss_pose_landmark_model\u001b[0;34m(model_complexity)\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mmodel_complexity\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     download_utils.download_oss_model(\n\u001b[0;32m--> 101\u001b[0;31m         'mediapipe/modules/pose_landmark/pose_landmark_heavy.tflite')\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mediapipe/python/solutions/download_utils.py\u001b[0m in \u001b[0;36mdownload_oss_model\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m     35\u001b[0m       raise ConnectionError('Cannot download ' + model_path +\n\u001b[1;32m     36\u001b[0m                             ' from Google Cloud Storage.')\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;34m\"\"\"copy data from file-like object fsrc to file-like object fdst\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "BG_COLOR = (192, 192, 192) # gray\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "with mp_pose.Pose(\n",
        "    static_image_mode=True,\n",
        "    model_complexity=2,\n",
        "    enable_segmentation=True,\n",
        "    min_detection_confidence=0.5) as pose:\n",
        "\n",
        "    image = cv2.imread(\"/content/drive/MyDrive/intershipdeepv/dataset/test/01-600x371.jpg\")\n",
        "    image_height, image_width, _ = image.shape\n",
        "    # Convert the BGR image to RGB before processing.\n",
        "    results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    if not results.pose_landmarks:\n",
        "      print(\"no one\")\n",
        "    leftshouder=(\n",
        "        \n",
        "        results.pose_landmarks.landmark[mp_pose.PoseLandmark(11).value].x * image_width,\n",
        "        results.pose_landmarks.landmark[mp_pose.PoseLandmark(11).value].y * image_height\n",
        "    );\n",
        "    la1=results.pose_landmarks.landmark[mp_pose.PoseLandmark(11).value].x * image_width\n",
        "    la2=results.pose_landmarks.landmark[mp_pose.PoseLandmark(11).value].y * image_height\n",
        "    \n",
        "    \n",
        "    rightshouder=(\n",
        "      \n",
        "        results.pose_landmarks.landmark[mp_pose.PoseLandmark(12).value].x * image_width ,\n",
        "        results.pose_landmarks.landmark[mp_pose.PoseLandmark(12).value].y * image_height\n",
        "    );\n",
        "   \n",
        "    \n",
        "    \n",
        "    annotated_image = image.copy()\n",
        "    # Draw segmentation on the image.\n",
        "    # To improve segmentation around boundaries, consider applying a joint\n",
        "    # bilateral filter to \"results.segmentation_mask\" with \"image\".\n",
        "    condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1\n",
        "    bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
        "    bg_image[:] = BG_COLOR\n",
        "    annotated_image = np.where(condition, annotated_image, bg_image)\n",
        "    # Draw pose landmarks on the image.\n",
        "    mp_drawing.draw_landmarks(annotated_image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
        "    mp_drawing.draw_landmarks(annotated_image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)    \n",
        "    mp_drawing.draw_landmarks(\n",
        "        annotated_image,\n",
        "        results.pose_landmarks,\n",
        "\n",
        "    mp_holistic.POSE_CONNECTIONS,\n",
        "        landmark_drawing_spec=mp_drawing_styles.\n",
        "        get_default_pose_landmarks_style())\n",
        "    mp_drawing.draw_landmarks(\n",
        "        annotated_image,\n",
        "        results.pose_landmarks,\n",
        "        mp_pose.POSE_CONNECTIONS,\n",
        "        landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
        "    cvs(annotated_image)\n",
        "    # cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)\n",
        "    # Plot pose world landmarks.\n",
        "    mp_drawing.plot_landmarks(\n",
        "        results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bqptVqrrFgQ",
        "outputId": "94208cf8-1d77-4cf5-9f92-c61f042d5b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YhtvmDgsQS_"
      },
      "outputs": [],
      "source": [
        "from PIL import Image,ImageEnhance\n",
        "\n",
        "img=Image.open(\"/content/drive/MyDrive/intershipdeepv/dataset/test/01-600x371.jpg\")\n",
        "\n",
        "img_brightness_obj=ImageEnhance.Brightness(img)\n",
        "for i in np.arange(0,2.5,0.1):\n",
        "  factor=float(i)\n",
        "  \n",
        "  enhanced_img=img_brightness_obj.enhance(factor)\n",
        "  enhanced_img.show()\n",
        "  i=int(i*10)\n",
        " \n",
        "  enhanced_img.save(\"/content/drive/MyDrive/intershipdeepv/dataset/test/img/brightness/{}.png\".format(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6dblrW1EpuR"
      },
      "outputs": [],
      "source": [
        "def mediapipe(dirc):\n",
        " \n",
        "  for filename in os.listdir(dirc):\n",
        "    o=0\n",
        "    print(o)\n",
        "    o+1;\n",
        "    img = cv2.imread(os.path.join(dirc,filename))    \n",
        "    image= cv2.resize(img,(257,257))\n",
        "    cvs(image)\n",
        "    mp_drawing_styles = mp.solutions.drawing_styles\n",
        "    mp_hands = mp.solutions.hands\n",
        "    hands = mp_hands.Hands(static_image_mode=True, max_num_hands=2, min_detection_confidence=0.7)\n",
        "    mp_drawing = mp.solutions.drawing_utils\n",
        "    mp_drawing_styles = mp.solutions.drawing_styles\n",
        "    a=[]\n",
        "    sample_img = image\n",
        "    plt.figure(figsize = [8, 8])\n",
        "    plt.title(\"Sample Image\");plt.axis('off');plt.imshow(sample_img[:,:,::-1]);plt.show()\n",
        "    results = hands.process(cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB))\n",
        "    x=[]\n",
        "    y=[]\n",
        "    sample_img = image\n",
        "    image_height, image_width, _ = image.shape\n",
        "    plt.figure(figsize = [8, 8])\n",
        "    img_copy = sample_img.copy()\n",
        "    if results.multi_hand_landmarks:\n",
        "      for hand_no, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
        "        mp_drawing.draw_landmarks(image = img_copy, landmark_list = hand_landmarks,\n",
        "                                  connections = mp_hands.HAND_CONNECTIONS)\n",
        "        fig = plt.figure(figsize = [8, 8])\n",
        "        img =plt.axis('off');plt.imshow(img_copy[:,:,::-1]);plt.show()\n",
        "\n",
        "      results = hands.process(cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    if results.multi_hand_landmarks:\n",
        "    \n",
        "        for hand_no, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
        "             print(f'HAND NUMBER: {hand_no+1}')\n",
        "             print('-----------------------')\n",
        "    \n",
        "             for i in range(4,21,4):\n",
        "                print(f'{mp_hands.HandLandmark(i).name}:')\n",
        "                x.append(hand_landmarks.landmark[mp_hands.HandLandmark(i).value].x*image_width)\n",
        "                y.append(hand_landmarks.landmark[mp_hands.HandLandmark(i).value].y*image_width)\n",
        "        print(x)\n",
        "        print(y)\n",
        "            \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlyEwbEMlvbs"
      },
      "outputs": [],
      "source": [
        "from PIL import Image,ImageEnhance\n",
        "dirc=\"/content/drive/MyDrive/intershipdeepv/dataset/test/img/contrast /\"\n",
        "img=Image.open(\"/content/drive/MyDrive/intershipdeepv/dataset/test/01-600x371.jpg\")\n",
        "\n",
        "img_brightness_obj=ImageEnhance.Contrast(img)\n",
        "for i in np.arange(0,3.5,0.1):\n",
        "  factor=float(i)\n",
        "  \n",
        "  enhanced_img=img_brightness_obj.enhance(factor)\n",
        "  enhanced_img.show()\n",
        "  i=int(i*10)\n",
        "  enhanced_img.save(\"/content/drive/MyDrive/intershipdeepv/dataset/test/img/contrast /{}.png\".format(i))\n",
        "mediapipe(dirc)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHAIqWsemTp3"
      },
      "outputs": [],
      "source": [
        "from PIL import Image,ImageEnhance\n",
        "dirc=\"/content/drive/MyDrive/intershipdeepv/dataset/test/img/sharpness/\"\n",
        "img=Image.open(\"/content/drive/MyDrive/intershipdeepv/dataset/test/01-600x371.jpg\")\n",
        "\n",
        "img_brightness_obj=ImageEnhance.Sharpness(img)\n",
        "for i in np.arange(0,3.5,0.1):\n",
        "  factor=float(i)\n",
        "  \n",
        "  enhanced_img=img_brightness_obj.enhance(factor)\n",
        "  enhanced_img.show()\n",
        "  i=int(i*10)\n",
        "  enhanced_img.save(\"/content/drive/MyDrive/intershipdeepv/dataset/test/img/sharpness/{}.png\".format(i))\n",
        "mediapipe(dirc)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bw6vFkqhIF1"
      },
      "source": [
        "#sign varition\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "o0SSzJk6sZyD",
        "outputId": "511b6ae9-4c41-42d2-ef09-aeb402c8e8d1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-285582d8c0b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmp_drawing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawing_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmp_drawing_styles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawing_styles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmp_holistic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholistic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mp' is not defined"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_holistic = mp.solutions.holistic\n",
        "\n",
        "# For static images:\n",
        "with mp_holistic.Holistic(\n",
        "    static_image_mode=True,\n",
        "    model_complexity=2,\n",
        "    enable_segmentation=True,\n",
        "    refine_face_landmarks=True) as holistic:\n",
        "  #for idx, file in enumerate(IMAGE_FILES):\n",
        "    image = cv2.imread(\"/content/drive/MyDrive/intershipdeepv/dataset/test/10-600x371.jpg\")\n",
        "    image_height, image_width, _ = image.shape\n",
        "    # Convert the BGR image to RGB before processing.\n",
        "    results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    if results.pose_landmarks:\n",
        "      print(\n",
        "          f'Nose coordinates: ('\n",
        "          f'{results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].x * image_width}, '\n",
        "          f'{results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].y * image_height})'\n",
        "      )\n",
        "   # if results.hand_landmarks:\n",
        "    #  print('hand_landmarks:', hand_landmarks)\n",
        "     # print(\n",
        "     #     f'Index finger tip coordinates: (',\n",
        "      #    f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image_width}, '\n",
        "       #   f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * image_height})'\n",
        "      #)\n",
        "\n",
        "    annotated_image = image.copy()\n",
        "    # Draw segmentation on the image.\n",
        "    # To improve segmentation around boundaries, consider applying a joint\n",
        "    # bilateral filter to \"results.segmentation_mask\" with \"image\".\n",
        "    condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1\n",
        "    bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
        "   \n",
        "    annotated_image = np.where(condition, annotated_image, bg_image)\n",
        "    # Draw pose, left and right hands, and face landmarks on the image.\n",
        "    #mp_drawing.draw_landmarks(\n",
        "        #annotated_image,\n",
        "        #results.hand_landmarks,\n",
        "         # mp_hands.HAND_CONNECTIONS,\n",
        "        # landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
        "    mp_drawing.draw_landmarks(annotated_image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,landmark_drawing_spec=mp_drawing_styles.\n",
        "        get_default_pose_landmarks_style())\n",
        "    mp_drawing.draw_landmarks(annotated_image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,landmark_drawing_spec=mp_drawing_styles.\n",
        "        get_default_pose_landmarks_style())    \n",
        "    mp_drawing.draw_landmarks(\n",
        "        annotated_image,\n",
        "        results.pose_landmarks,\n",
        "\n",
        "        mp_holistic.POSE_CONNECTIONS,\n",
        "        landmark_drawing_spec=mp_drawing_styles.\n",
        "        get_default_pose_landmarks_style())\n",
        "  #  cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)\n",
        "    # Plot pose world landmarks.\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GruOafRG5ohU"
      },
      "outputs": [],
      "source": [
        "import mediapipe as mp\n",
        "mp_holistic = mp.solutions.holistic\n",
        "\n",
        "help(mp_holistic.Holistic)\n",
        "mp_drawing = mp.solutions.drawing_utils \n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "image = cv2.imread(\"/content/drive/MyDrive/intershipdeepv/dataset/test/10-600x371.jpg\")\n",
        "with mp_holistic.Holistic(\n",
        "    static_image_mode=True, min_detection_confidence=0.5, model_complexity=2) as holistic:\n",
        "    # Convert the BGR image to RGB and process it with MediaPipe Pose.\n",
        "    results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    \n",
        "    # Print nose coordinates.\n",
        "    image_hight, image_width, _ = image.shape\n",
        "    if results.pose_landmarks:\n",
        "      print(\n",
        "        f'Nose coordinates: ('\n",
        "        f'{results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].x * image_width}, '\n",
        "        f'{results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].y * image_hight})'\n",
        "      )\n",
        "\n",
        "    # Draw pose landmarks.\n",
        "    print(f'Pose landmarks of :')\n",
        "    annotated_image = image.copy()\n",
        "    mp_drawing.draw_landmarks(annotated_image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
        "    mp_drawing.draw_landmarks(annotated_image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
        "    mp_drawing.draw_landmarks(\n",
        "        annotated_image,\n",
        "        results.face_landmarks,\n",
        "        mp_holistic.FACEMESH_TESSELATION,\n",
        "        landmark_drawing_spec=None,\n",
        "        connection_drawing_spec=mp_drawing_styles\n",
        "        .get_default_face_mesh_tesselation_style())\n",
        "    mp_drawing.draw_landmarks(\n",
        "        annotated_image,\n",
        "        results.pose_landmarks,\n",
        "        mp_holistic.POSE_CONNECTIONS,\n",
        "        landmark_drawing_spec=mp_drawing_styles.\n",
        "        get_default_pose_landmarks_style())\n",
        "    cvs(annotated_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHKyX00D5oTV"
      },
      "outputs": [],
      "source": [
        "i=1;\n",
        "for p in os.listdir(\"/content/drive/MyDrive/intershipdeepv/dataset/aug20th/Aug20th/Unofficial\"):\n",
        "   # os.mkdir(\"/content/drive/MyDrive/intershipdeepv/dataset/aug20th/unofficial/{}\".format(str(p)))\n",
        "    dir=(\"/content/drive/MyDrive/intershipdeepv/dataset/aug20th/unofficial/{}\".format(str(p)))\n",
        "    video=\"/content/drive/MyDrive/intershipdeepv/dataset/aug20th/Aug20th/Unofficial/{}\".format(str(p))\n",
        "    print(video)\n",
        "    print(dir)\n",
        "    !ffmpeg -i \"video\" -vf fps=30  \"dir/%d\"\n",
        "\n",
        "#/content/drive/MyDrive/intershipdeepv/dataset/aug20th/Aug20th/Unofficial/unofficial-video-1.webm\n",
        "    #!ffmpeg -i l -vf fps=30 \"\"\n",
        "#/content/drive/MyDrive/intershipdeepv/dataset/aug20th/unofficial "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWu_-UOq9qtT"
      },
      "outputs": [],
      "source": [
        "for p in os.listdir(\"/content/drive/MyDrive/intershipdeepv/dataset/aug20th/Aug20th/Unofficial\"):\n",
        "   vc = cv2.VideoCapture(\"/content/drive/MyDrive/intershipdeepv/dataset/aug20th/Aug20th/Unofficial/{}\".format(str(p)))\n",
        "   c = 1\n",
        "   if vc.isOpened():\n",
        "        rval, frame = vc.read()\n",
        "   else:\n",
        "        rval = False\n",
        "\n",
        "   while rval:\n",
        "        rval, frame = vc.read()\n",
        "        cv2.imwrite(os.path.join(\"/content/drive/MyDrive/intershipdeepv/dataset/aug20th/unofficial/{}\".format(p), '/%d.png', frame))\n",
        "        c = c + 1\n",
        "        cv2.waitKey(1)\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}